import json
import os
import shutil
import uuid

import redis
from typing import Optional, List

from fastapi import FastAPI, Depends, HTTPException, Form, UploadFile, File, Request
from fastapi.middleware.cors import CORSMiddleware
from sqlalchemy.orm import Session
from starlette.responses import FileResponse
from starlette.staticfiles import StaticFiles

from common import models, schemas
from common.database import SessionLocal
from common.models import TaskStatus
from common.logger import debug_log
from services.gateway.core.conversation import init_batch
from services.gateway.core.dispatch import dispatch_tasks
from services.gateway.core.file import save_uploaded_files

app = FastAPI(title="AI Task Gateway", version="2.0.0")

# --- CORS é…ç½® ---
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# --- Redis è¿æ¥ ---
REDIS_HOST = os.getenv("REDIS_HOST", "127.0.0.1")
REDIS_PORT = int(os.getenv("REDIS_PORT", 6379))
redis_client = redis.Redis(host=REDIS_HOST, port=REDIS_PORT, db=0)


# --- ä¾èµ–æ³¨å…¥ ---
def get_db():
    db = SessionLocal()
    try:
        yield db
    finally:
        db.close()


# ==========================================
# API æ¥å£å®šä¹‰
# ==========================================
current_dir = os.path.dirname(os.path.abspath(__file__))
static_dir = os.path.join(current_dir, "static")
if not os.path.exists(static_dir):
    raise RuntimeError(f"âŒ æ‰¾ä¸åˆ°é™æ€ç›®å½•: {static_dir}ï¼Œè¯·ç¡®ä¿å·²åˆ›å»º 'static' æ–‡ä»¶å¤¹å¹¶æ”¾å…¥ index.html")
app.mount("/static", StaticFiles(directory=static_dir), name="static")

current_dir = os.path.dirname(os.path.abspath(__file__))
UPLOAD_DIR = os.path.join(current_dir, "uploads")
os.makedirs(UPLOAD_DIR, exist_ok=True)

app.mount("/files", StaticFiles(directory=UPLOAD_DIR), name="files")

@app.get("/")
async def read_root():
    # åŒæ ·ä½¿ç”¨ç»å¯¹è·¯å¾„
    index_file = os.path.join(static_dir, "index.html")
    return FileResponse(index_file)

@app.get("/health")
def health_check():
    return {"status": "ok", "redis": redis_client.ping()}


# === 1. æäº¤ä»»åŠ¡ ===
@app.post("/v1/chat/completions", response_model=schemas.BatchSubmitResponse)
def create_chat_task(
    # âš ï¸ å¿…é¡»æŠŠåŸæ¥çš„ Pydantic body æ”¹ä¸º Form è¡¨å•å­—æ®µ
    prompt: str = Form(...),
    model: str = Form("gemini-2.5-flash"),
    conversation_id: Optional[str] = Form(None),
    files: List[UploadFile] = File(None),  # âœ¨ æ¥æ”¶æ–‡ä»¶
    mode: str = Form("text"),
    db: Session = Depends(get_db)
):
    """
    æ¥æ”¶ç”¨æˆ·è¯·æ±‚ï¼Œåˆ›å»º Batchï¼Œæ‹†åˆ†ä¸ºå¤šä¸ª Task å¹¶åˆ†å‘
    æ”¯æŒ request.model = "gemini-flash, qwen-7b"
    """
    try:
        debug_log("=" * 40, "REQUEST")
        debug_log(f"æ”¶åˆ°è¯·æ±‚ | Models: {model}", "REQUEST")

        # 1. ä¿å­˜æ–‡ä»¶
        saved_file_paths = save_uploaded_files(files, UPLOAD_DIR)

        # 2. åˆå§‹åŒ–æ•°æ®åº“ Batch
        new_batch, conversation = init_batch(db, prompt, model, conversation_id)

        # 3. æ‹†åˆ†å¹¶åˆ†å‘ä»»åŠ¡ (æ³¨å…¥ redis_client)
        created_task_ids = dispatch_tasks(
            db=db,
            redis_client=redis_client,
            batch_id=new_batch.batch_id,
            conversation_id=conversation.conversation_id,
            prompt=prompt,
            model_config=model,
            mode=mode,
            file_paths=saved_file_paths
        )

        return {
            "batch_id": new_batch.batch_id,
            "conversation_id": conversation.conversation_id,
            "message": "Tasks dispatched successfully",
            "task_ids": created_task_ids
        }

    except Exception as e:
        import traceback
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=f"Server Error: {str(e)}")


@app.get("/v1/tasks/{task_id}", response_model=schemas.TaskQueryResponse)
def get_task_status(task_id: str, db: Session = Depends(get_db)):
    """
        æŸ¥è¯¢ä»»åŠ¡çŠ¶æ€APIç«¯ç‚¹

        åŠŸèƒ½:
            æ ¹æ®ä»»åŠ¡IDä»æ•°æ®åº“æŸ¥è¯¢ä»»åŠ¡çš„è¯¦ç»†ä¿¡æ¯ï¼ŒåŒ…æ‹¬çŠ¶æ€ã€ç»“æœç­‰

        å‚æ•°:
            task_id: è¦æŸ¥è¯¢çš„ä»»åŠ¡IDï¼ˆè·¯å¾„å‚æ•°ï¼‰
            db: æ•°æ®åº“ä¼šè¯ï¼ˆè‡ªåŠ¨æ³¨å…¥ï¼‰

        è¿”å›:
            TaskQueryResponse: åŒ…å«ä»»åŠ¡æ‰€æœ‰è¯¦ç»†ä¿¡æ¯çš„å“åº”

        å¼‚å¸¸:
            HTTP 404: ä»»åŠ¡ä¸å­˜åœ¨
        """
    debug_log(f"æŸ¥è¯¢ä»»åŠ¡çŠ¶æ€: {task_id}", "REQUEST")
    task = db.query(models.Task).filter(models.Task.task_id == task_id).first()
    if not task:
        debug_log(f"ä»»åŠ¡æœªæ‰¾åˆ°: {task_id}", "WARNING")
        raise HTTPException(status_code=404, detail="Task not found")

    debug_log(f"ä»»åŠ¡ {task_id} çŠ¶æ€: {task.status}", "INFO")
    return task




@app.get("/v1/batches/{batch_id}", response_model=schemas.BatchQueryResponse)
def get_batch_result(batch_id: str, db: Session = Depends(get_db)):
    """
    å‰ç«¯è½®è¯¢æ­¤æ¥å£ï¼Œè·å–æ•´ä¸ª Batch çš„æ‰§è¡ŒçŠ¶æ€å’Œæ‰€æœ‰å­æ¨¡å‹çš„ç»“æœ
    """
    batch = db.query(models.ChatBatch).filter(models.ChatBatch.batch_id == batch_id).first()
    if not batch:
        raise HTTPException(status_code=404, detail="Batch ID not found")

    # æ£€æŸ¥æ•´ä½“çŠ¶æ€ (å¯é€‰ä¼˜åŒ–ï¼šå¦‚æœæ‰€æœ‰ Task éƒ½å®Œæˆäº†ï¼Œæ›´æ–° Batch çŠ¶æ€ä¸º COMPLETED)
    # è¿™é‡Œç®€å•å¤„ç†ï¼šç›´æ¥è¿”å› Batch ä¿¡æ¯å’Œå®ƒå…³è”çš„ Tasks

    return {
        "batch_id": batch.batch_id,
        "status": batch.status,
        "user_prompt": batch.user_prompt,
        "created_at": batch.created_at,
        "results": batch.tasks  # SQLAlchemy relationship ä¼šè‡ªåŠ¨æ‹‰å–å­ä»»åŠ¡
    }


@app.get("/v1/conversations/{conversation_id}/history")
def get_history(conversation_id: str, request: Request, db: Session = Depends(get_db)):
    # 1. è·å–è¯¥ä¼šè¯ä¸‹æ‰€æœ‰æˆåŠŸçš„ä»»åŠ¡ï¼ŒæŒ‰æ—¶é—´æ’åº
    tasks = db.query(models.Task).filter(
        models.Task.conversation_id == conversation_id,
        models.Task.status != TaskStatus.FAILED
    ).order_by(models.Task.created_at.asc()).all()

    # 2. æ„å»ºæ¶ˆæ¯åˆ—è¡¨
    messages = []
    base_url = str(request.base_url).rstrip("/")

    for t in tasks:
        # --- å¤„ç†æ–‡ä»¶è·¯å¾„ ---
        file_urls = []
        if t.file_paths:
            # å…¼å®¹å¤„ç†ï¼šå¦‚æœæ˜¯å­—ç¬¦ä¸²å…ˆè½¬åˆ—è¡¨
            paths = t.file_paths if isinstance(t.file_paths, list) else json.loads(t.file_paths)
            for p in paths:
                # æå–æ–‡ä»¶å (ä¾‹å¦‚ /app/uploads/abc.jpg -> abc.jpg)
                filename = os.path.basename(p)
                # ç”Ÿæˆå®Œæ•´è®¿é—®é“¾æ¥
                file_urls.append(f"{base_url}/files/{filename}")

        # A. ç”¨æˆ·æé—®
        messages.append({
            "role": "user",
            "content": t.prompt,
            "model": t.model_name,
            "files": file_urls  # âœ¨ æŠŠæ–‡ä»¶ URL ä¼ ç»™å‰ç«¯
        })

        # ğŸ”¥ ä¿®æ”¹ï¼šå¦‚æœè¿˜åœ¨è·‘ï¼Œç»™ä¸ªç‰¹æ®Šæ ‡è®°
        if t.status == TaskStatus.SUCCESS and t.response_text:
            messages.append({"role": "assistant", "content": t.response_text, "model": t.model_name})
        elif t.status in [TaskStatus.PENDING, TaskStatus.PROCESSING]:
            # å‘Šè¯‰å‰ç«¯è¿™æ˜¯ä¸€ä¸ªæ­£åœ¨ç”Ÿæˆçš„å ä½ç¬¦
            messages.append({"role": "assistant", "content": "thinking...", "model": t.model_name, "is_loading": True})

    # ç›´æ¥è¿”å›åˆ—è¡¨å³å¯ï¼Œå‰ç«¯é€šå¸¸ç›´æ¥æ¸²æŸ“è¿™ä¸ªæ•°ç»„
    return messages


@app.get("/v1/conversations")
def list_conversations(limit: int = 20, db: Session = Depends(get_db)):
    """
    è·å–æœ€è¿‘çš„ä¼šè¯åˆ—è¡¨ï¼ŒæŒ‰æ›´æ–°æ—¶é—´å€’åºæ’åˆ—
    """
    conversations = db.query(models.Conversation) \
        .order_by(models.Conversation.updated_at.desc()) \
        .limit(limit) \
        .all()

    return {
        "conversations": [
            {
                "conversation_id": c.conversation_id,
                "title": c.title or "æ–°å¯¹è¯",  # å¦‚æœæ²¡æœ‰æ ‡é¢˜ï¼Œæ˜¾ç¤ºé»˜è®¤æ–‡æ¡ˆ
                "modified": c.updated_at
            }
            for c in conversations
        ]
    }


if __name__ == "__main__":
    import uvicorn

    # å¯åŠ¨å‘½ä»¤: python gateway/server.py
    uvicorn.run(app, host="0.0.0.0", port=8000)