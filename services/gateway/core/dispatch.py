# --- æ ¸å¿ƒé€»è¾‘ï¼šè·¯ç”±åˆ†å‘ ---
import json
import uuid
import random
from typing import List, Optional, Type

from sqlalchemy.orm import Session
from common import models
from common.models import TaskStatus, GeminiServiceNode  # ðŸ‘ˆ å¯¼å…¥èŠ‚ç‚¹æ¨¡åž‹
from common.logger import debug_log


def dispatch_to_stream(redis_client, task_payload: dict) -> str:
    """æ ¹æ®æ¨¡åž‹åç§°å†³å®šæŠ•é€’åˆ°å“ªä¸ª Redis Stream"""
    model_name = task_payload.get("model", "").lower()

    stream_key = "gemini_stream"  # é»˜è®¤å…œåº•

    if "qwen" in model_name or "åƒé—®" in model_name:
        stream_key = "qwen_stream"
    elif "deepseek" in model_name:
        stream_key = "deepseek_stream"
    elif "gemini" in model_name:
        stream_key = "gemini_stream"
    elif "sd" in model_name or "stable" in model_name:
        stream_key = "sd_stream"

    # æ‰§è¡ŒæŠ•é€’ (ä½¿ç”¨ä¼ å…¥çš„ redis_client)
    redis_client.xadd(stream_key, {"payload": json.dumps(task_payload)})
    return stream_key


def _select_target_nodes(
        db: Session,
        concurrency: int,
        node_model: Optional[Type] = None
) -> List[Optional[str]]:
    """
    æ ¹æ®å¹¶å‘æ•°å’ŒèŠ‚ç‚¹æ¨¡åž‹ï¼Œè¿”å›žç›®æ ‡èŠ‚ç‚¹ URL åˆ—è¡¨ã€‚
    ä¾‹å¦‚ concurrency=2 -> è¿”å›ž ['http://node1...', 'http://node2...']
    å¦‚æžœæ‰¾ä¸åˆ°è¶³å¤ŸèŠ‚ç‚¹ï¼Œä½ç½®ä¼šå¡«ä¸º None (è¡¨ç¤ºç”± Worker è‡ªåŠ¨è·¯ç”±)
    """
    target_urls = [None] * concurrency  # é»˜è®¤å…¨æ˜¯ [None, None]

    if node_model and concurrency > 0:
        # æŸ¥è¯¢æ‰€æœ‰å¥åº·èŠ‚ç‚¹
        # ä¼˜åŒ–ç­–ç•¥ï¼šå¯ä»¥æŒ‰ current_tasks å‡åºæŽ’åˆ—ï¼Œä¼˜å…ˆé€‰ç©ºé—²çš„
        available_nodes = db.query(node_model).filter(
            node_model.status == "HEALTHY"
        ).order_by(node_model.current_tasks.asc()).limit(10).all()

        if available_nodes:
            # å¦‚æžœèŠ‚ç‚¹å¤Ÿå¤šï¼Œéšæœºé€‰ unique çš„èŠ‚ç‚¹ï¼›ä¸å¤Ÿå°±å…è®¸é‡å¤æˆ–å¡«å…¥ None
            count_to_pick = min(len(available_nodes), concurrency)
            selected_nodes = random.sample(available_nodes, count_to_pick)

            for i in range(count_to_pick):
                target_urls[i] = selected_nodes[i].node_url

    return target_urls


def _dispatch_single_task(
        db: Session,
        redis_client,
        batch_id: str,
        conversation_id: str,
        prompt: str,
        base_model_name: str,
        mode: str,
        file_paths: List[str],
        target_node_url: Optional[str] = None,
        suffix: str = ""
) -> str:
    """
    åˆ›å»ºä¸€ä¸ª Task è®°å½•å¹¶æŽ¨é€åˆ° Redis
    """
    # 1. æž„é€ å”¯ä¸€çš„æ˜¾ç¤ºåç§° (æ–¹ä¾¿å‰ç«¯åŒºåˆ† Node-1, Node-2)
    display_model_name = base_model_name
    if suffix:
        display_model_name = f"{base_model_name} {suffix}"

    # 2. åˆ›å»ºæ•°æ®åº“è®°å½•
    worker_prompt = prompt
    if mode == "image":
        worker_prompt = "ä½ ä½œä¸º AI å›¾åƒç”Ÿæˆå¼•æ“Žï¼Œéœ€åœ¨å“åº”ä¸­ç›´æŽ¥è¾“å‡ºç”Ÿæˆçš„å›¾ç‰‡\n" + prompt

    new_task = models.Task(
        task_id=str(uuid.uuid4()),
        batch_id=batch_id,
        conversation_id=conversation_id,
        prompt=prompt,
        model_name=display_model_name,  # å­˜å…¥æ•°æ®åº“çš„åç§°
        status=TaskStatus.PENDING,
        task_type="IMAGE" if mode == "image" else ("MULTIMODAL" if file_paths else "TEXT"),
        file_paths=file_paths
    )
    db.add(new_task)
    db.commit()
    db.refresh(new_task)

    # 3. ç»„è£… Payload (åŒ…å« target_node_url)
    task_payload = {
        "task_id": new_task.task_id,
        "conversation_id": conversation_id,
        "prompt": worker_prompt,
        "model": base_model_name,  # ä¼ ç»™ Worker çš„çœŸå®žæ¨¡åž‹å
        "file_paths": file_paths,
        "target_node_url": target_node_url  # ðŸ‘ˆ å…³é”®å­—æ®µ
    }

    try:
        queue = dispatch_to_stream(redis_client, task_payload)
        node_info = target_node_url or "Auto-Route"
        debug_log(f" -> [åˆ†å‘] Task: {new_task.task_id} | Node: {node_info}", "INFO")
    except Exception as e:
        new_task.status = TaskStatus.FAILED
        new_task.error_msg = f"MQ Error: {str(e)}"
        db.commit()
        debug_log(f"âŒ åˆ†å‘å¤±è´¥: {e}", "ERROR")

    return new_task.task_id


def dispatch_tasks(
        db: Session,
        redis_client,
        batch_id: str,
        conversation_id: str,
        prompt: str,
        model_config: str,
        mode: str,
        file_paths: List[str],
        gemini_concurrency: int = 1
) -> List[str]:
    model_list = [m.strip() for m in model_config.split(",") if m.strip()]
    if not model_list:
        model_list = ["gemini-2.5-flash"]

    created_task_ids = []

    for model_name in model_list:
        # é»˜è®¤é…ç½®
        concurrency = 1
        node_model = None

        # âœ¨ 2. é’ˆå¯¹ Gemini å¯ç”¨åŠ¨æ€å¹¶å‘
        if "gemini" in model_name.lower():
            # è¿™é‡Œçš„é€»è¾‘å¯¹åº”å‰ç«¯çš„ "x2" å¼€å…³
            # é™åˆ¶æœ€å° 1ï¼Œæœ€å¤§ 2 (é˜²æ­¢ä»¥åŽå‰ç«¯ä¼ é”™æˆ–è€…è¢«æ»¥ç”¨)
            concurrency = min(max(gemini_concurrency, 1), 2)
            node_model = GeminiServiceNode

        # (æœªæ¥æ‰©å±•)
        # elif "deepseek" in model_name: ...

        # 3. èŽ·å–ç›®æ ‡èŠ‚ç‚¹ (å¦‚æžœå¹¶å‘æ˜¯1ï¼Œè¿™é‡Œå°±æ˜¯ [None] æˆ– [url])
        target_urls = _select_target_nodes(db, concurrency, node_model)

        # 4. å¾ªçŽ¯åˆ†å‘
        for i, target_url in enumerate(target_urls):
            # âœ¨ 3. åŽç¼€ä¼˜åŒ–ï¼šåªæœ‰åœ¨å¼€å¯å¹¶å‘æ—¶æ‰æ˜¾ç¤º (#1, #2)
            # å¦‚æžœ concurrency == 1ï¼Œsuffix ä¸ºç©ºï¼Œç”¨æˆ·çœ‹åˆ°çš„è¿˜æ˜¯çº¯å‡€çš„ "Gemini 2.5 Flash"
            suffix = f"(#{i + 1})" if concurrency > 1 else ""

            task_id = _dispatch_single_task(
                db=db,
                redis_client=redis_client,
                batch_id=batch_id,
                conversation_id=conversation_id,
                prompt=prompt,
                base_model_name=model_name,
                mode=mode,
                file_paths=file_paths,
                target_node_url=target_url,
                suffix=suffix
            )
            created_task_ids.append(task_id)

    return created_task_ids