# services/gateway/core/dispatch.py

import json
import uuid
import random
from typing import List, Optional, Type

from sqlalchemy.orm import Session
from common import models
from common.models import TaskStatus, GeminiServiceNode
from common.logger import debug_log


def dispatch_to_stream(redis_client, task_payload: dict, optional_stream_key: str = None) -> str:
    """
    æ ¹æ®æ¨¡å‹åç§°æˆ–å¼ºåˆ¶æŒ‡å®šå‚æ•°ï¼Œå†³å®šæŠ•é€’åˆ°å“ªä¸ª Redis Stream
    :param optional_stream_key: å¼ºåˆ¶æŒ‡å®š Stream Key (ç”¨äºåˆ†ç‰‡æ¶ˆè´¹)
    """
    # 1. å¦‚æœå¼ºåˆ¶æŒ‡å®šäº† Key (ä¾‹å¦‚ gemini_stream_1)ï¼Œä¼˜å…ˆçº§æœ€é«˜
    if optional_stream_key:
        stream_key = optional_stream_key
    else:
        # 2. å¦åˆ™èµ°è‡ªåŠ¨è·¯ç”±é€»è¾‘
        model_name = task_payload.get("model", "").lower()
        stream_key = "qwen_stream"  # é»˜è®¤å…œåº•

        if "qwen" in model_name or "åƒé—®" in model_name:
            stream_key = "qwen_stream"
        elif "deepseek" in model_name:
            stream_key = "deepseek_stream"
        elif "gemini" in model_name:
            stream_key = "gemini_stream"
        elif "sd" in model_name or "stable" in model_name:
            stream_key = "sd_stream"

    # æ‰§è¡ŒæŠ•é€’
    redis_client.xadd(stream_key, {"payload": json.dumps(task_payload)})
    return stream_key


def _select_target_nodes(
        db: Session,
        concurrency: int,
        node_model: Optional[Type] = None
) -> List[Optional[str]]:
    """
    æ ¹æ®å¹¶å‘æ•°å’ŒèŠ‚ç‚¹æ¨¡å‹ï¼Œè¿”å›ç›®æ ‡èŠ‚ç‚¹ URL åˆ—è¡¨ã€‚
    """
    target_urls = [None] * concurrency  # é»˜è®¤å…¨æ˜¯ [None, None]

    if node_model and concurrency > 0:
        # ç­–ç•¥ï¼šä¼˜å…ˆé€‰è´Ÿè½½æœ€ä½çš„å¥åº·èŠ‚ç‚¹
        available_nodes = db.query(node_model).filter(
            node_model.status == "HEALTHY"
        ).order_by(node_model.current_tasks.asc()).limit(10).all()

        if available_nodes:
            # éšæœºé€‰æ‹©ä»¥é¿å…æƒŠç¾¤æ•ˆåº”ï¼Œä½†ä¼˜å…ˆé€‰ç©ºé—²çš„
            count_to_pick = min(len(available_nodes), concurrency)
            # random.sample ä¸ä¼šé‡å¤é€‰æ‹©åŒä¸€ä¸ªèŠ‚ç‚¹ï¼ˆå¦‚æœèŠ‚ç‚¹æ•°å¤Ÿï¼‰
            # å¦‚æœä½ å¸Œæœ›å…è®¸å¤ç”¨åŒä¸€ä¸ªèŠ‚ç‚¹ï¼ˆèŠ‚ç‚¹æ•° < å¹¶å‘æ•°ï¼‰ï¼Œå¯ä»¥ç”¨ random.choices
            if len(available_nodes) >= count_to_pick:
                selected_nodes = random.sample(available_nodes, count_to_pick)
            else:
                # èŠ‚ç‚¹ä¸å¤Ÿæ—¶ï¼Œå…è®¸å¤ç”¨
                selected_nodes = random.choices(available_nodes, k=count_to_pick)

            for i in range(count_to_pick):
                target_urls[i] = selected_nodes[i].node_url

    return target_urls


def _dispatch_single_task(
        db: Session,
        redis_client,
        batch_id: str,
        conversation_id: str,
        prompt: str,
        base_model_name: str,
        mode: str,
        file_paths: List[str],
        target_node_url: Optional[str] = None,
        suffix: str = "",
        target_stream: Optional[str] = None  # ğŸ‘ˆ æ–°å¢å‚æ•°ï¼šæŒ‡å®šç›®æ ‡ Stream
) -> str:
    """
    åˆ›å»ºä¸€ä¸ª Task æ•°æ®åº“è®°å½•å¹¶æ¨é€åˆ° Redis
    """
    # 1. æ„é€ æ˜¾ç¤ºçš„åç§° (ä¾‹å¦‚ "Gemini (#1)")
    display_model_name = base_model_name
    if suffix:
        display_model_name = f"{base_model_name} {suffix}"

    # 2. åˆ›å»ºæ•°æ®åº“è®°å½•
    worker_prompt = prompt
    if mode == "image":
        worker_prompt = "ä½ ä½œä¸º AI å›¾åƒç”Ÿæˆå¼•æ“ï¼Œéœ€åœ¨å“åº”ä¸­ç›´æ¥è¾“å‡ºç”Ÿæˆçš„å›¾ç‰‡\n" + prompt

    new_task = models.Task(
        task_id=str(uuid.uuid4()),
        batch_id=batch_id,
        conversation_id=conversation_id,
        prompt=prompt,
        model_name=display_model_name,
        status=TaskStatus.PENDING,
        task_type="IMAGE" if mode == "image" else ("MULTIMODAL" if file_paths else "TEXT"),
        file_paths=file_paths
    )
    db.add(new_task)
    db.commit()
    db.refresh(new_task)

    # 3. ç»„è£… Payload
    task_payload = {
        "task_id": new_task.task_id,
        "conversation_id": conversation_id,
        "prompt": worker_prompt,
        "model": base_model_name,
        "file_paths": file_paths,
        "target_node_url": target_node_url  # æ³¨å…¥æŒ‡å®šèŠ‚ç‚¹
    }

    try:
        # âœ¨ ä¼ é€’ target_stream
        queue = dispatch_to_stream(redis_client, task_payload, optional_stream_key=target_stream)

        node_info = target_node_url or "Auto"
        stream_info = target_stream or "Auto"
        debug_log(f" -> [åˆ†å‘] Task: {new_task.task_id} | Node: {node_info} | Stream: {queue}", "INFO")
    except Exception as e:
        new_task.status = TaskStatus.FAILED
        new_task.error_msg = f"MQ Error: {str(e)}"
        db.commit()
        debug_log(f"âŒ åˆ†å‘å¤±è´¥: {e}", "ERROR")

    return new_task.task_id


def dispatch_tasks(
        db: Session,
        redis_client,
        batch_id: str,
        conversation_id: str,
        prompt: str,
        model_config: str,
        mode: str,
        file_paths: List[str],
        gemini_concurrency: int = 1
) -> List[str]:
    raw_list = [m.strip() for m in model_config.split(",") if m.strip()]
    model_list = [m for m in raw_list if m.lower() != "on"]
    if not model_list:
        model_list = ["gemini-2.5-flash"]

    created_task_ids = []

    for model_name in model_list:
        concurrency = 1
        node_model = None
        is_gemini_concurrent = False

        # === Gemini ç‰¹æ®Šå¤„ç†é€»è¾‘ ===
        if "gemini" in model_name.lower():
            # é™åˆ¶å¹¶å‘èŒƒå›´ [1, 2]
            concurrency = min(max(gemini_concurrency, 1), 2)
            node_model = GeminiServiceNode
            if concurrency > 1:
                is_gemini_concurrent = True

        # 1. é€‰å‡º N ä¸ªèŠ‚ç‚¹ (ä»ç„¶éœ€è¦é€‰å‡ºç›®æ ‡èŠ‚ç‚¹ï¼Œäº¤ç»™ Worker å»æŠ¢å æˆ–ç›´æ¥ä½¿ç”¨)
        target_urls = _select_target_nodes(db, concurrency, node_model)

        # 2. å¾ªç¯åˆ†å‘ä»»åŠ¡
        for i, target_url in enumerate(target_urls):
            suffix = ""
            # ğŸ”¥ğŸ”¥ğŸ”¥ ä¿®æ”¹ç‚¹ï¼šç»Ÿä¸€ Stream Key ğŸ”¥ğŸ”¥ğŸ”¥
            target_stream = None

            if "gemini" in model_name.lower():
                # é…åˆ Consumer Groupï¼ŒRedis ä¼šè‡ªåŠ¨æŠŠè¿™ä¸¤æ¡æ¶ˆæ¯åˆ†ç»™ä¸åŒçš„ Worker
                target_stream = "gemini_stream"

                if is_gemini_concurrent:
                    # ä»…ä¿ç•™åç¼€é€»è¾‘ï¼Œç”¨äºåœ¨å‰ç«¯åŒºåˆ† Task #1 å’Œ #2
                    suffix = f"(#{i + 1})"

            # 3. åˆ›å»ºå¹¶å‘é€
            task_id = _dispatch_single_task(
                db=db,
                redis_client=redis_client,
                batch_id=batch_id,
                conversation_id=conversation_id,
                prompt=prompt,
                base_model_name=model_name,
                mode=mode,
                file_paths=file_paths,
                target_node_url=target_url,
                suffix=suffix,
                target_stream=target_stream
            )
            created_task_ids.append(task_id)

    return created_task_ids