import json
import os
import time
import socket
from datetime import datetime
from pathlib import Path
from requests.exceptions import Timeout, ConnectTimeout, RequestException
import redis
import requests
from dotenv import load_dotenv

from common import models
from common.database import SessionLocal
from common.logger import debug_log
from common.models import TaskStatus
from services.workers.core import parse_and_validate, claim_task, mark_task_failed, recover_pending_tasks

# --- 1. ç¯å¢ƒé…ç½® ---
current_file_path = Path(__file__).resolve()
project_root = current_file_path.parent.parent.parent
env_path = project_root / ".env"

if env_path.exists():
    load_dotenv(env_path)

# --- 2. å…¨å±€é…ç½® ---
REDIS_HOST = os.getenv("REDIS_HOST", "127.0.0.1")
REDIS_PORT = int(os.getenv("REDIS_PORT", 6379))

# ğŸ”¥ DeepSeek é…ç½®
DEEPSEEK_SERVICE_URL = os.getenv("DEEPSEEK_SERVICE_URL", "http://192.168.202.155:61414/v1/chat/completions")
DEEPSEEK_API_KEY = os.getenv("DEEPSEEK_API_KEY", "")  # å¦‚æœæ˜¯æœ¬åœ° Ollamaï¼Œè¿™ä¸ªå¯ä»¥ä¸ºç©º

# é˜Ÿåˆ—é…ç½® (å¿…é¡»ä¸ server.py ä¸­çš„ dispatch_task é€»è¾‘ä¸€è‡´)
STREAM_KEY = os.getenv("STREAM_KEY", "deepseek_stream")
GROUP_NAME = os.getenv("GROUP_NAME", "deepseek_workers_group")

worker_identity = os.getenv("DEEPSEEK_WORKER_ID")
if not worker_identity:
    worker_identity = f"deepseek-{socket.gethostname()}-{os.getpid()}"
CONSUMER_NAME = f"worker-{worker_identity}"

redis_client = redis.Redis(host=REDIS_HOST, port=REDIS_PORT, db=0)


def init_stream():
    """åˆå§‹åŒ– Stream"""
    try:
        redis_client.xgroup_create(STREAM_KEY, GROUP_NAME, id='0', mkstream=True)
        debug_log(f"ğŸ‹ DeepSeek æ¶ˆè´¹è€…ç»„ {GROUP_NAME} å°±ç»ª", "INFO")
    except redis.exceptions.ResponseError as e:
        if "BUSYGROUP" not in str(e):
            raise e


def process_message(message_id, message_data, check_idempotency=True):
    """å¤„ç†å•æ¡æ¶ˆæ¯"""
    db = SessionLocal()
    task_data = parse_and_validate(
        redis_client, STREAM_KEY, GROUP_NAME, message_id, message_data, CONSUMER_NAME
    )

    # å¦‚æœè¿”å› Noneï¼Œè¯´æ˜æ˜¯çƒ‚æ¶ˆæ¯ä¸”å·²ç»è¢« helper å¤„ç†æ‰äº†ï¼Œç›´æ¥æ”¶å·¥
    if not task_data:
        db.close()
        return

    # =========================================================
    # 2. æå–æ•°æ® (æ­¤æ—¶ task_data è‚¯å®šæ˜¯å®‰å…¨çš„å­—å…¸)
    # =========================================================
    task_id = task_data.get('task_id')
    conversation_id = task_data.get('conversation_id')
    prompt = task_data.get('prompt')
    model = task_data.get('model')

    try:
        # --- å¹‚ç­‰æ€§æ£€æŸ¥ ---
        if check_idempotency:
            # ç›´æ¥è°ƒç”¨å…¬å…±å‡½æ•°å°è¯•æŠ¢å 
            if not claim_task(db, task_id):
                # å¦‚æœæŠ¢å å¤±è´¥ (è¿”å›False)ï¼Œè¯´æ˜ä»»åŠ¡æ­£åœ¨è·‘æˆ–è·‘å®Œäº†
                # ç›´æ¥ ACK å‘Šè¯‰ Redis "è¿™äº‹ä¸ç”¨æˆ‘ç®¡äº†"
                redis_client.xack(STREAM_KEY, GROUP_NAME, message_id)
                return

        debug_log(f"ğŸ‹ DeepSeek å¼€å§‹æ€è€ƒ: {task_id} (Model: {model})", "REQUEST")
        start_time = time.time()

        # --- 2. æ„é€ è¯·æ±‚ Payload ---
        # å…¼å®¹ OpenAI æ¥å£æ ¼å¼ (DeepSeek å®˜æ–¹å’Œ Ollama éƒ½æ”¯æŒè¿™ä¸ªæ ¼å¼)
        payload = {
            "model": model,
            "messages": [{"role": "user", "content": prompt}],
            "stream": False,
            # DeepSeek ç‰¹æœ‰å‚æ•° (å¯é€‰ï¼Œå¦‚æœæ˜¯ R1 å»ºè®®è®¾ä¸º 0.6)
            "temperature": 0.6
        }

        # æ„é€  Headers (é€‚é…å®˜æ–¹ API éœ€è¦ Key çš„æƒ…å†µ)
        headers = {"Content-Type": "application/json"}
        if DEEPSEEK_API_KEY:
            headers["Authorization"] = f"Bearer {DEEPSEEK_API_KEY}"

        # --- 3. è°ƒç”¨åç«¯ API ---
        debug_log(f"å‘é€è¯·æ±‚è‡³: {DEEPSEEK_SERVICE_URL}", "INFO")
        response = requests.post(
            DEEPSEEK_SERVICE_URL,
            json=payload,
            headers=headers,
            timeout=300  # DeepSeek R1 æ€è€ƒæ—¶é—´å¯èƒ½è¾ƒé•¿ï¼Œå»ºè®®è¶…æ—¶è®¾é•¿ä¸€ç‚¹
        )

        if response.status_code == 200:
            res_json = response.json()

            # è§£æ OpenAI æ ¼å¼å“åº”
            if 'choices' in res_json and len(res_json['choices']) > 0:
                ai_text = res_json['choices'][0]['message']['content']

                # (å¯é€‰) å¦‚æœæ˜¯ DeepSeek R1ï¼Œè¿”å›å†…å®¹å¯èƒ½åŒ…å« <think> æ ‡ç­¾
                # è¿™é‡Œå¯ä»¥åšä¸€äº›æ¸…æ´—ï¼Œæˆ–è€…ç›´æ¥å­˜å…¥æ•°æ®åº“äº¤ç»™å‰ç«¯å¤„ç†
            else:
                ai_text = str(res_json)

            # æ›´æ–°æ•°æ®åº“
            task = db.query(models.Task).filter(models.Task.task_id == task_id).first()
            if task:
                task.response_text = ai_text
                task.status = TaskStatus.SUCCESS
                task.cost_time = round(time.time() - start_time, 2)

                # æ›´æ–°ä¼šè¯æ—¶é—´
                if conversation_id:
                    conv = db.query(models.Conversation).filter(
                        models.Conversation.conversation_id == conversation_id).first()
                    if conv:
                        conv.updated_at = datetime.now()

                db.commit()
                debug_log(f"âœ… å›ç­”å®Œæ¯• (è€—æ—¶: {task.cost_time}s)", "SUCCESS")

            redis_client.xack(STREAM_KEY, GROUP_NAME, message_id)

        else:
            error_msg = f"DeepSeek API Error: {response.status_code} - {response.text[:200]}"
            debug_log(error_msg, "ERROR")
            mark_task_failed(db, task_id, error_msg)
            redis_client.xack(STREAM_KEY, GROUP_NAME, message_id)

    except ConnectTimeout:
        error_msg = "æ— æ³•è¿æ¥åˆ° AI æœåŠ¡ (Connection Timeout)ã€‚è¯·æ£€æŸ¥ API åœ°å€æˆ–é˜²ç«å¢™é…ç½®ã€‚"
        debug_log(f"ğŸ”Œ {error_msg}", "ERROR")
        mark_task_failed(db, task_id, "ç³»ç»Ÿå†…éƒ¨è¿æ¥å¼‚å¸¸ï¼Œè¯·è”ç³»ç®¡ç†å‘˜")
        redis_client.xack(STREAM_KEY, GROUP_NAME, message_id)

    except Timeout:
        error_msg = "AI ç”Ÿæˆè¶…æ—¶ï¼ˆè¶…è¿‡æŒ‡å®šæ—¶é—´æ— å“åº”ï¼‰ï¼Œè¯·ç¨åé‡è¯•ã€‚"
        debug_log(f"â³ {error_msg}", "ERROR")
        mark_task_failed(db, task_id, error_msg)
        redis_client.xack(STREAM_KEY, GROUP_NAME, message_id)

    except RequestException as e:
        error_msg = f"ç½‘ç»œè¿æ¥å¼‚å¸¸: {str(e)}"
        debug_log(error_msg, "ERROR")
        mark_task_failed(db, task_id, "åç«¯æœåŠ¡è¿æ¥ä¸­æ–­")
        redis_client.xack(STREAM_KEY, GROUP_NAME, message_id)

    except Exception as e:
        db.rollback()
        debug_log(f"Worker å†…éƒ¨å´©æºƒ: {e}", "ERROR")
        mark_task_failed(db, task_id, "ç³»ç»Ÿå†…éƒ¨å¤„ç†é”™è¯¯")
        redis_client.xack(STREAM_KEY, GROUP_NAME, message_id)

    finally:
        db.close()



def start_worker():
    debug_log("=" * 40, "INFO")
    debug_log(f"ğŸš€ DeepSeek Worker å¯åŠ¨ | ç›‘å¬: {STREAM_KEY}", "INFO")

    init_stream()
    recover_pending_tasks(
        redis_client=redis_client,
        stream_key=STREAM_KEY,
        group_name=GROUP_NAME,
        consumer_name=CONSUMER_NAME,
        process_callback=process_message  # <--- å‡½æ•°ä½œä¸ºå‚æ•°ä¼ é€’
    )

    while True:
        try:
            # é˜»å¡è¯»å–
            response = redis_client.xreadgroup(
                GROUP_NAME, CONSUMER_NAME, {STREAM_KEY: '>'}, count=1, block=2000
            )
            if response:
                for stream, msgs in response:
                    for msg_id, msg_data in msgs:
                        process_message(msg_id, msg_data, check_idempotency=False)
        except Exception as e:
            debug_log(f"ä¸»å¾ªç¯å¼‚å¸¸: {e}", "ERROR")
            time.sleep(5)


if __name__ == "__main__":
    start_worker()