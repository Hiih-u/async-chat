# workers/gemini/gemini_worker.py
import os
import time
import socket
from pathlib import Path

from requests.exceptions import RequestException, Timeout, ConnectTimeout
import redis
import requests
from dotenv import load_dotenv

from common import database
from services.workers.core import build_conversation_context
from services.workers.core import upload_files_to_downstream
from common.logger import debug_log
from services.workers.core import (
    parse_and_validate,     # æ¶ˆæ¯å±‚
    claim_task,             # çŠ¶æ€å±‚
    mark_task_failed,       # çŠ¶æ€å±‚
    recover_pending_tasks,  # æ¶ˆæ¯å±‚
    get_database_target_url,   # è·¯ç”±å±‚
    process_ai_result       # ä¸šåŠ¡å±‚
)
from services.workers.core.task_state import update_node_load

# --- 1. ç¯å¢ƒé…ç½®ä¸åŠ è½½ ---
current_file_path = Path(__file__).resolve()
project_root = current_file_path.parent.parent.parent.parent
env_path = project_root / ".env"

if env_path.exists():
    load_dotenv(env_path)
    print(f"âœ… å·²åŠ è½½ç¯å¢ƒå˜é‡: {env_path}")
else:
    print(f"âš ï¸ æœªæ‰¾åˆ°ç¯å¢ƒå˜é‡æ–‡ä»¶: {env_path}")

# --- 2. å…¨å±€é…ç½® ---
REDIS_HOST = os.getenv("REDIS_HOST", "127.0.0.1")
REDIS_PORT = int(os.getenv("REDIS_PORT", 6379))

DEBUG = True
STREAM_KEY = os.getenv("STREAM_KEY", "gemini_stream")
GROUP_NAME = os.getenv("GROUP_NAME", "gemini_workers_group")

# Worker èº«ä»½æ ‡è¯†
worker_identity = os.getenv("GEMINI_WORKER_ID")
if not worker_identity:
    worker_identity = f"{socket.gethostname()}-{os.getpid()}"
    print(f"âš ï¸ è­¦å‘Š: æœªé…ç½® WORKER_IDï¼Œä½¿ç”¨éšæœºID: {worker_identity}")
CONSUMER_NAME = f"worker-{worker_identity}"

# åˆå§‹åŒ– Redis è¿æ¥
redis_client = redis.Redis(host=REDIS_HOST, port=REDIS_PORT, db=0)

GEMINI_REFUSAL_KEYWORDS = [
    "æ‚¨ç™»å½•äº†å—",
    "æ— æ³•ä¸ºæ‚¨åˆ›å»ºä»»ä½•å›¾ç‰‡",
    "åœ°åŒºå°šæœªå¼€é€š",
    "æ— æ³•åˆ›å»ºå›¾ç‰‡",
    "I cannot create images",
    "yet available to create images"
]

def init_stream():
    """åˆå§‹åŒ– Stream å’Œ æ¶ˆè´¹è€…ç»„"""
    try:
        redis_client.xgroup_create(STREAM_KEY, GROUP_NAME, id='0', mkstream=True)
        debug_log(f"æ¶ˆè´¹è€…ç»„ {GROUP_NAME} å°±ç»ª", "INFO")
    except redis.exceptions.ResponseError as e:
        if "BUSYGROUP" in str(e):
            debug_log(f"æ¶ˆè´¹è€…ç»„ {GROUP_NAME} å·²å­˜åœ¨", "INFO")
        else:
            raise e

def process_message(message_id, message_data, check_idempotency=True):
    """
    å¤„ç†å•æ¡æ¶ˆæ¯çš„æ ¸å¿ƒé€»è¾‘ (ä¼˜åŒ–ç‰ˆï¼šè¶…æ—¶ç†”æ–­ + è½¯æ‹’ç»æ£€æµ‹)
    """
    node_url_for_release = None

    db = database.SessionLocal()
    task_data = parse_and_validate(
        redis_client, STREAM_KEY, GROUP_NAME, message_id, message_data, CONSUMER_NAME
    )

    # å¦‚æœè¿”å› Noneï¼Œè¯´æ˜æ˜¯çƒ‚æ¶ˆæ¯ä¸”å·²ç»è¢« helper å¤„ç†æ‰äº†ï¼Œç›´æ¥æ”¶å·¥
    if not task_data:
        db.close()
        return

    task_id = task_data.get('task_id')
    conversation_id = task_data.get('conversation_id')
    prompt = task_data.get('prompt')
    model = task_data.get('model')
    local_file_paths = task_data.get('file_paths', [])

    try:
        # =========================================================
        # ğŸ”¥ å¹‚ç­‰æ€§æ£€æŸ¥
        # =========================================================
        if check_idempotency:
            # ç›´æ¥è°ƒç”¨å…¬å…±å‡½æ•°å°è¯•æŠ¢å 
            if not claim_task(db, task_id):
                # å¦‚æœæŠ¢å å¤±è´¥ (è¿”å›False)ï¼Œè¯´æ˜ä»»åŠ¡æ­£åœ¨è·‘æˆ–è·‘å®Œäº†
                # ç›´æ¥ ACK å‘Šè¯‰ Redis "è¿™äº‹ä¸ç”¨æˆ‘ç®¡äº†"
                redis_client.xack(STREAM_KEY, GROUP_NAME, message_id)
                return
        # =========================================================

        debug_log(f"å¼€å§‹å¤„ç†: {task_id}", "REQUEST")

        # --- 2. è°ƒç”¨ä¸‹æ¸¸ AI æœåŠ¡ ---
        route_result = get_database_target_url(db, conversation_id)

        if not route_result:
            error_msg = "æš‚æ— å¯ç”¨ Gemini èŠ‚ç‚¹ (æ•°æ®åº“æ— æ´»è·ƒè®°å½•)"
            mark_task_failed(db, task_id, error_msg)
            redis_client.xack(STREAM_KEY, GROUP_NAME, message_id)
            return

        # è§£åŒ… tuple
        target_url, is_node_changed = route_result

        if not target_url:
            error_msg = "æš‚æ— å¯ç”¨ Gemini èŠ‚ç‚¹ (æ•°æ®åº“æ— æ´»è·ƒè®°å½•)"
            debug_log(f"âŒ {error_msg}", "ERROR")  # å»ºè®®åŠ ä¸€æ¡æ—¥å¿—
            mark_task_failed(db, task_id, error_msg)
            redis_client.xack(STREAM_KEY, GROUP_NAME, message_id)
            return

        update_node_load(db, target_url, 1)
        node_url_for_release = target_url
        target_base_url = target_url.replace("/v1/chat/completions", "")
        debug_log(f"å‘é€è¯·æ±‚åˆ°: {target_url}", "REQUEST")

        remote_file_paths = []
        if local_file_paths:
            # è°ƒç”¨ä¸Šé¢çš„è¾…åŠ©å‡½æ•°ï¼ŒæŠŠæ–‡ä»¶æ¨é€åˆ°å…·ä½“çš„ Worker èŠ‚ç‚¹
            remote_file_paths = upload_files_to_downstream(target_base_url, local_file_paths)

            if local_file_paths and not remote_file_paths:
                error_msg = "æ–‡ä»¶ä¸Šä¼ å¤±è´¥ï¼Œæ— æ³•å¤„ç†å¤šæ¨¡æ€è¯·æ±‚"
                mark_task_failed(db, task_id, error_msg)
                redis_client.xack(...)
                return  # ç›´æ¥ç»“æŸï¼Œè®°å¾— finally ä¼šé‡Šæ”¾èµ„æº

        headers = {"Content-Type": "application/json"}

        messages_payload = []
        if is_node_changed:
            # A. å‘ç”ŸèŠ‚ç‚¹æ¼‚ç§»ï¼ˆæˆ–é¦–å­—å¯¹è¯ï¼‰-> å¿…é¡»æ„å»ºå…¨é‡å†å²
            debug_log(f"ğŸ”„ æ£€æµ‹åˆ°èŠ‚ç‚¹å˜æ›´ï¼Œæ­£åœ¨åŒæ­¥ä¸Šä¸‹æ–‡å†å²...", "INFO")
            messages_payload = build_conversation_context(db, conversation_id, prompt)
        else:
            # B. èŠ‚ç‚¹æ²¡å˜
            messages_payload = [{"role": "user", "content": prompt}]

            # 3. ç»„è£…æœ€ç»ˆè¯·æ±‚æ•°æ®
        payload = {
            "model": model,
            "conversation_id": conversation_id,
            "messages": messages_payload,
            "files": remote_file_paths if remote_file_paths else None  # âœ¨ å¡«å…¥ä¸‹æ¸¸è¿”å›çš„è·¯å¾„
        }

        start_time = time.time()
        response = requests.post(target_url, json=payload, headers={"Content-Type": "application/json"}, timeout=120)


        if response.status_code == 200:
            # === HTTP æˆåŠŸï¼Œä½†éœ€æ£€æŸ¥ä¸šåŠ¡å†…å®¹ ===
            res_json = response.json()
            ai_text = res_json['choices'][0]['message']['content']
            cost_time = round(time.time() - start_time, 2)

            # ğŸ”¥ æ ¸å¿ƒä¿®æ”¹ï¼šä¸€è¡Œä»£ç æå®š å®¡æŸ¥ + ä¿å­˜ + çŠ¶æ€æ›´æ–°
            process_ai_result(
                db,
                task_id,
                ai_text,
                cost_time,
                conversation_id,
                refusal_keywords=GEMINI_REFUSAL_KEYWORDS  # ä¼ å…¥ç”±äº Gemini ç‰¹æ€§çš„æ‹’ç»è¯
            )

            # æ— è®ºæˆåŠŸè¿˜æ˜¯è¢«æ‹¦æˆªï¼Œéƒ½ ACK æ‰ï¼Œé¿å…é‡å¤æ¶ˆè´¹
            redis_client.xack(STREAM_KEY, GROUP_NAME, message_id)

        else:
            # === HTTP çŠ¶æ€ç é”™è¯¯ (é 200) ===
            error_msg = f"Gemini API Error: {response.status_code} - {response.text[:100]}"
            debug_log(error_msg, "ERROR")
            mark_task_failed(db, task_id, error_msg)
            redis_client.xack(STREAM_KEY, GROUP_NAME, message_id)

    except ConnectTimeout:
        error_msg = "æ— æ³•è¿æ¥åˆ° AI æœåŠ¡ (Connection Timeout)ã€‚è¯·æ£€æŸ¥ API åœ°å€æˆ–é˜²ç«å¢™é…ç½®ã€‚"
        debug_log(f"ğŸ”Œ {error_msg}", "ERROR")

        mark_task_failed(db, task_id, "ç³»ç»Ÿå†…éƒ¨è¿æ¥å¼‚å¸¸ï¼Œè¯·è”ç³»ç®¡ç†å‘˜")
        redis_client.xack(STREAM_KEY, GROUP_NAME, message_id)

        # 2. å†æ•è·è¯»å–è¶…æ—¶ (çœŸæ­£çš„ >120ç§’)
    except Timeout:
        error_msg = "AI ç”Ÿæˆè¶…æ—¶ï¼ˆè¶…è¿‡ 2 åˆ†é’Ÿæ— å“åº”ï¼‰ï¼Œè¯·ç¨åé‡è¯•ã€‚"
        debug_log(f"â³ {error_msg}", "ERROR")

        mark_task_failed(db, task_id, error_msg)
        redis_client.xack(STREAM_KEY, GROUP_NAME, message_id)

    except RequestException as e:
        # å…¶ä»–ç½‘ç»œé”™è¯¯ (è¿æ¥è¢«æ‹’ã€DNSè§£æå¤±è´¥ç­‰)
        error_msg = f"ç½‘ç»œè¿æ¥å¼‚å¸¸: {str(e)}"
        debug_log(error_msg, "ERROR")

        mark_task_failed(db, task_id, "åç«¯æœåŠ¡è¿æ¥ä¸­æ–­")
        redis_client.xack(STREAM_KEY, GROUP_NAME, message_id)

    except Exception as e:
        db.rollback()
        # ä»£ç é€»è¾‘å´©æºƒ
        debug_log(f"Worker å†…éƒ¨å´©æºƒ: {e}", "ERROR")
        mark_task_failed(db, task_id, "ç³»ç»Ÿå†…éƒ¨å¤„ç†é”™è¯¯")
        redis_client.xack(STREAM_KEY, GROUP_NAME, message_id)

    finally:
        if node_url_for_release:
            update_node_load(db, node_url_for_release, -1)
        db.close()



def start_worker():
    debug_log("=" * 40, "INFO")
    debug_log(f"ğŸš€ Stream Worker å¯åŠ¨ (Fail Fast Mode): {CONSUMER_NAME}", "INFO")

    init_stream()

    # 1. ä»…åœ¨å¯åŠ¨æ—¶æ£€æŸ¥ä¸€æ¬¡
    recover_pending_tasks(
        redis_client=redis_client,
        stream_key=STREAM_KEY,
        group_name=GROUP_NAME,
        consumer_name=CONSUMER_NAME,
        process_callback=process_message  # <--- å‡½æ•°ä½œä¸ºå‚æ•°ä¼ é€’
    )

    debug_log("è¿›å…¥ä¸»å¾ªç¯ç›‘å¬...", "INFO")

    # 2. ä¸»å¾ªç¯ (ä¸å†æœ‰å®šæ—¶æ£€æŸ¥)
    while True:
        try:
            # é˜»å¡è¯»å–æ–°æ¶ˆæ¯
            response = redis_client.xreadgroup(
                GROUP_NAME, CONSUMER_NAME, {STREAM_KEY: '>'}, count=1, block=2000
            )

            if not response:
                continue

            stream_name, messages = response[0]
            for message_id, message_data in messages:
                process_message(message_id, message_data, check_idempotency=False)

        except Exception as e:
            debug_log(f"ä¸»å¾ªç¯å¼‚å¸¸: {e}", "ERROR")
            time.sleep(5)  # é˜²æ­¢ Redis æŒ‚äº†å¯¼è‡´æ­»å¾ªç¯åˆ·å±


if __name__ == "__main__":
    start_worker()