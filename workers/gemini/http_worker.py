# workers/gemini/http_worker.py
import json
import os
import time
import socket
from pathlib import Path
from datetime import datetime

import redis
import requests
from dotenv import load_dotenv
from sqlalchemy.orm import Session

# å¯¼å…¥å…±äº«æ¨¡å—
from shared import models, database
from shared.models import TaskStatus
from shared.utils import log_error, debug_log

# --- 1. ç¯å¢ƒé…ç½®ä¸åŠ è½½ ---
# å¼ºåˆ¶åŠ è½½é¡¹ç›®æ ¹ç›®å½•çš„ .env
current_file_path = Path(__file__).resolve()
project_root = current_file_path.parent.parent.parent
env_path = project_root / ".env"

if env_path.exists():
    load_dotenv(env_path)
    print(f"âœ… å·²åŠ è½½ç¯å¢ƒå˜é‡: {env_path}")
else:
    print(f"âš ï¸ æœªæ‰¾åˆ°ç¯å¢ƒå˜é‡æ–‡ä»¶: {env_path}")

# --- 2. å…¨å±€é…ç½® ---
REDIS_HOST = os.getenv("REDIS_HOST", "127.0.0.1")
REDIS_PORT = int(os.getenv("REDIS_PORT", 6379))
GEMINI_SERVICE_URL = os.getenv("GEMINI_SERVICE_URL", "http://192.168.202.155:61028/v1/chat/completions")
DEBUG = True

# Stream é…ç½®
STREAM_KEY = "gemini_stream"
GROUP_NAME = "gemini_workers_group"

# Worker èº«ä»½æ ‡è¯†
worker_identity = os.getenv("WORKER_ID")
if not worker_identity:
    worker_identity = f"{socket.gethostname()}-{os.getpid()}"
    print(f"âš ï¸ è­¦å‘Š: æœªé…ç½® WORKER_IDï¼Œä½¿ç”¨éšæœºID: {worker_identity}")
CONSUMER_NAME = f"worker-{worker_identity}"

# åˆå§‹åŒ– Redis è¿æ¥ (decode_responses=False æ‰èƒ½å¤„ç† Stream çš„ bytes key)
redis_client = redis.Redis(host=REDIS_HOST, port=REDIS_PORT, db=0)

def init_stream():
    """åˆå§‹åŒ– Stream å’Œ æ¶ˆè´¹è€…ç»„"""
    try:
        redis_client.xgroup_create(STREAM_KEY, GROUP_NAME, id='0', mkstream=True)
        debug_log(f"æ¶ˆè´¹è€…ç»„ {GROUP_NAME} å°±ç»ª", "INFO")
    except redis.exceptions.ResponseError as e:
        if "BUSYGROUP" in str(e):
            debug_log(f"æ¶ˆè´¹è€…ç»„ {GROUP_NAME} å·²å­˜åœ¨", "INFO")
        else:
            raise e


def process_message(message_id, message_data, check_idempotency=True):

    """
    å¤„ç†å•æ¡æ¶ˆæ¯çš„æ ¸å¿ƒé€»è¾‘
    :param message_id: Redis Stream Message ID
    :param message_data: Redis Stream Message Data
    :param check_idempotency: (å…³é”®ä¼˜åŒ–)
           True  -> å…ˆæŸ¥ DBï¼Œå¦‚æœæ˜¯ 'SUCCESS' åˆ™è·³è¿‡ (ç”¨äº Crash æ¢å¤çš„æ—§ä»»åŠ¡)
           False -> ä¸æŸ¥ DBï¼Œç›´æ¥è·‘ (ç”¨äºåˆšæ”¶åˆ°çš„æ–°ä»»åŠ¡ï¼Œæå‡é€Ÿåº¦)
    """
    db = database.SessionLocal()
    task_id = "UNKNOWN"
    existing_task = None  # ç”¨äºå­˜å‚¨æ•°æ®åº“å¯¹è±¡

    try:
        # --- 1. è§£æ Redis æ¶ˆæ¯ ---
        payload_bytes = message_data.get(b'payload')
        if not payload_bytes:
            debug_log(f"æ¶ˆæ¯æ ¼å¼é”™è¯¯ (ç¼º payload): {message_data}", "ERROR")
            redis_client.xack(STREAM_KEY, GROUP_NAME, message_id)
            return

        task_data = json.loads(payload_bytes)
        task_id = task_data.get('task_id')
        conversation_id = task_data.get('conversation_id')
        prompt = task_data.get('prompt')
        model = task_data.get('model')

        # =========================================================
        # ğŸ”¥ ä¼˜åŒ–ç‚¹ï¼šåŒºåˆ†æ–°æ—§ä»»åŠ¡çš„å¹‚ç­‰æ€§æ£€æŸ¥
        # =========================================================
        if check_idempotency:
            # å¦‚æœæ˜¯æ—§ä»»åŠ¡ï¼Œå¾ˆå¯èƒ½ä¸Šæ¬¡å·²ç»è·‘å®Œäº†ä½†æ²¡ ACKï¼Œæ‰€ä»¥å¿…é¡»æŸ¥åº“
            existing_task = db.query(models.Task).filter(models.Task.task_id == task_id).first()

            if existing_task and existing_task.status == TaskStatus.SUCCESS:
                debug_log(f"â™»ï¸ [å¹‚ç­‰æ‹¦æˆª] ä»»åŠ¡ {task_id} å·²åœ¨åº“ä¸­å®Œæˆï¼Œè¡¥å‘ ACK", "WARNING")
                redis_client.xack(STREAM_KEY, GROUP_NAME, message_id)
                return
        # =========================================================

        debug_log(f"å¼€å§‹å¤„ç†: {task_id} | æ¨¡å¼: {'æ—§ä»»åŠ¡é‡è¯•' if check_idempotency else 'æ–°ä»»åŠ¡'}", "REQUEST")

        # --- 2. è°ƒç”¨ä¸‹æ¸¸ AI æœåŠ¡ ---
        payload = {
            "model": model,
            "conversation_id": conversation_id,
            "messages": [{"role": "user", "content": prompt}]
        }

        start_time = time.time()

        # Requests åŒæ­¥è°ƒç”¨ (æœªæ¥å¯å‡çº§ä¸º httpx å¼‚æ­¥)
        response = requests.post(GEMINI_SERVICE_URL, json=payload, timeout=120)

        if response.status_code == 200:
            # === ä¸šåŠ¡æˆåŠŸ ===
            res_json = response.json()
            ai_text = res_json['choices'][0]['message']['content']

            # æ›´æ–°æ•°æ®åº“
            # å¦‚æœæ˜¯æ–°ä»»åŠ¡(check=False)ï¼Œexisting_task è¿˜æ˜¯ Noneï¼Œéœ€è¦æŸ¥å‡ºæ¥æ›´æ–°
            # å¦‚æœæ˜¯æ—§ä»»åŠ¡(check=True)ä¸”æ²¡è¢«æ‹¦æˆªï¼Œè¯´æ˜ existing_task æ˜¯ PENDING/FAILEDï¼Œç›´æ¥ç”¨å³å¯
            if not existing_task:
                existing_task = db.query(models.Task).filter(models.Task.task_id == task_id).first()

            if existing_task:
                existing_task.response_text = ai_text
                existing_task.status = TaskStatus.SUCCESS
                existing_task.cost_time = round(time.time() - start_time, 2)

                # æ›´æ–°ä¼šè¯æ—¶é—´
                conv = db.query(models.Conversation).filter(
                    models.Conversation.conversation_id == conversation_id).first()
                if conv:
                    conv.updated_at = datetime.now()

                db.commit()
                debug_log(f"ä»»åŠ¡å®Œæˆ: {task_id} (è€—æ—¶: {existing_task.cost_time:.2f}s)", "SUCCESS")

            # ğŸ”¥ åªæœ‰ä¸šåŠ¡æˆåŠŸè½åº“äº†ï¼Œæ‰ ACK
            redis_client.xack(STREAM_KEY, GROUP_NAME, message_id)

        else:
            # === ä¸šåŠ¡å¤±è´¥ (API é”™è¯¯) ===
            error_msg = f"Gemini API Error: {response.status_code} - {response.text[:50]}"
            debug_log(error_msg, "ERROR")

            # è®°å½•æ—¥å¿—
            log_error("Worker-Gemini", error_msg, task_id)
            _mark_failed(db, task_id, error_msg)

            # è¿™é‡Œçš„ç­–ç•¥ï¼šå¦‚æœæ˜¯æ˜ç¡®çš„ 4xx/500 é”™è¯¯ï¼Œå»ºè®® ACK æ‰é˜²æ­¢æ­»å¾ªç¯
            # å¦‚æœä½ å¸Œæœ›å®ƒé‡è¯•ï¼Œå¯ä»¥æ³¨é‡Šæ‰ä¸‹é¢è¿™è¡Œ
            redis_client.xack(STREAM_KEY, GROUP_NAME, message_id)

    except (json.JSONDecodeError, UnicodeDecodeError):
        debug_log(f"è„æ•°æ®ä¸¢å¼ƒ: {message_id}", "ERROR")
        redis_client.xack(STREAM_KEY, GROUP_NAME, message_id)

    except requests.exceptions.RequestException as e:
        # === ç½‘ç»œå¼‚å¸¸ (ä¿ç•™ Pending) ===
        debug_log(f"ç½‘ç»œè¯·æ±‚å¤±è´¥ (å°†é‡è¯•): {e}", "ERROR")
        log_error("Worker-Gemini", "ç½‘ç»œè¿æ¥å¼‚å¸¸", task_id, e)
        # âš ï¸ å…³é”®ï¼šè¿™é‡Œä¸ ACKï¼Œä¹Ÿä¸æ ‡è®° FAILED (æˆ–è€…æ ‡ FAILED ä½†ä¿ç•™ä»»åŠ¡)
        # è¿™æ ·ä¸‹æ¬¡å¿ƒè·³æ£€æŸ¥ (recover_pending_tasks) ä¼šè‡ªåŠ¨é‡è¯•

    except Exception as e:
        # === ä»£ç é€»è¾‘å´©æºƒ ===
        debug_log(f"Worker å†…éƒ¨å´©æºƒ: {e}", "ERROR")
        log_error("Worker-Gemini", "æœªçŸ¥å¼‚å¸¸", task_id, e)
        _mark_failed(db, task_id, str(e))
        redis_client.xack(STREAM_KEY, GROUP_NAME, message_id)

    finally:
        db.close()


def _mark_failed(db, task_id, msg):
    """è¾…åŠ©ï¼šæ ‡è®°æ•°æ®åº“ä»»åŠ¡ä¸ºå¤±è´¥"""
    try:
        if task_id and task_id != "UNKNOWN":
            task = db.query(models.Task).filter(models.Task.task_id == task_id).first()
            if task:
                task.status = TaskStatus.FAILED
                task.error_msg = msg
                db.commit()
    except Exception as e:
        db.rollback()
        print(f"ä¸¥é‡: æ— æ³•æ›´æ–°å¤±è´¥çŠ¶æ€ {e}")


def recover_pending_tasks():
    """
    å´©æºƒæ¢å¤ + å¿ƒè·³æ£€æµ‹
    æ£€æŸ¥é‚£äº› "å±äºæˆ‘ï¼Œä½†å¤ªä¹…æ²¡ ACK" çš„æ¶ˆæ¯
    """
    try:
        # id='0' è¡¨ç¤ºè·å–æ‰€æœ‰ Pending çš„æ¶ˆæ¯
        response = redis_client.xreadgroup(
            GROUP_NAME, CONSUMER_NAME, {STREAM_KEY: '0'}, count=10, block=None
        )

        if response:
            stream_name, messages = response[0]
            if messages:
                debug_log(f"â™»ï¸ å‘ç° {len(messages)} ä¸ªæŒ‚èµ·ä»»åŠ¡ï¼Œæ­£åœ¨æ¢å¤...", "WARNING")
                for message_id, message_data in messages:
                    # ğŸ”¥ é‡ç‚¹ï¼šæ—§ä»»åŠ¡å¿…é¡»å¼€å¯å¹‚ç­‰æ€§æ£€æŸ¥ (True)
                    process_message(message_id, message_data, check_idempotency=True)
                debug_log("âœ… æŒ‚èµ·ä»»åŠ¡å¤„ç†å®Œæ¯•", "INFO")
    except Exception as e:
        debug_log(f"æ¢å¤ Pending ä»»åŠ¡å¤±è´¥: {e}", "ERROR")


def start_worker():
    debug_log("=" * 40, "INFO")
    debug_log(f"ğŸš€ Stream Worker å¯åŠ¨: {CONSUMER_NAME}", "INFO")

    # 1. åˆå§‹åŒ–
    init_stream()

    # 2. å¯åŠ¨æ—¶å…ˆå…¨é‡æ¢å¤ä¸€æ¬¡
    recover_pending_tasks()

    # å®šä¹‰å¿ƒè·³é—´éš” (ç§’)
    CHECK_INTERVAL = 60
    last_check_time = time.time()

    debug_log("è¿›å…¥ä¸»å¾ªç¯ç›‘å¬...", "INFO")

    # 3. ä¸»å¾ªç¯
    while True:
        try:
            # --- A. å‘¨æœŸæ€§å¿ƒè·³ (è¡¥æ¼æœºåˆ¶) ---
            current_time = time.time()
            if current_time - last_check_time > CHECK_INTERVAL:
                recover_pending_tasks()  # è¿™é‡Œé¢è°ƒç”¨çš„ process_message å¸¦æœ‰ True å‚æ•°
                last_check_time = current_time
                debug_log("æ‰§è¡Œå‘¨æœŸæ€§å¾…å¤„ç†ä»»åŠ¡æ£€æŸ¥", "INFO")

            # --- B. é˜»å¡è¯»å–æ–°æ¶ˆæ¯ ---
            # '>' è¡¨ç¤ºåªè¯»æœ€æ–°çš„æœªåˆ†é…æ¶ˆæ¯
            response = redis_client.xreadgroup(
                GROUP_NAME, CONSUMER_NAME, {STREAM_KEY: '>'}, count=1, block=2000
            )

            if not response:
                continue

            stream_name, messages = response[0]
            for message_id, message_data in messages:
                # ğŸ”¥ é‡ç‚¹ï¼šæ–°ä»»åŠ¡å…³é—­å¹‚ç­‰æ€§æ£€æŸ¥ (False)ï¼Œæå¤§æå‡æ€§èƒ½
                process_message(message_id, message_data, check_idempotency=False)

        except Exception as e:
            debug_log(f"ä¸»å¾ªç¯å¼‚å¸¸: {e}", "ERROR")
            time.sleep(5)  # é˜²æ­¢æ­»å¾ªç¯åˆ·å±


if __name__ == "__main__":
    start_worker()