# workers/gemini/gemini_worker.py
import json
import os
import time
import socket
from pathlib import Path
from datetime import datetime
import random

import nacos
from requests.exceptions import RequestException, Timeout, ConnectTimeout
import redis
import requests
from dotenv import load_dotenv

from shared import database
from shared.utils.logger import debug_log
from shared.core import (
    parse_and_validate,     # æ¶ˆæ¯å±‚
    claim_task,             # çŠ¶æ€å±‚
    mark_task_failed,       # çŠ¶æ€å±‚
    recover_pending_tasks,  # æ¶ˆæ¯å±‚
    get_nacos_target_url,   # è·¯ç”±å±‚
    process_ai_result       # ä¸šåŠ¡å±‚
)

# --- 1. ç¯å¢ƒé…ç½®ä¸åŠ è½½ ---
current_file_path = Path(__file__).resolve()
project_root = current_file_path.parent.parent.parent
env_path = project_root / ".env"

if env_path.exists():
    load_dotenv(env_path)
    print(f"âœ… å·²åŠ è½½ç¯å¢ƒå˜é‡: {env_path}")
else:
    print(f"âš ï¸ æœªæ‰¾åˆ°ç¯å¢ƒå˜é‡æ–‡ä»¶: {env_path}")

# --- 2. å…¨å±€é…ç½® ---
REDIS_HOST = os.getenv("REDIS_HOST", "127.0.0.1")
REDIS_PORT = int(os.getenv("REDIS_PORT", 6379))

NACOS_SERVER_ADDR = os.getenv("NACOS_SERVER_ADDR", "127.0.0.1:8848")
NACOS_NAMESPACE = "public"
SERVICE_NAME = "gemini-service"

DEBUG = True
STREAM_KEY = os.getenv("STREAM_KEY", "gemini_stream")
GROUP_NAME = os.getenv("GROUP_NAME", "gemini_workers_group")

# Worker èº«ä»½æ ‡è¯†
worker_identity = os.getenv("GEMINI_WORKER_ID")
if not worker_identity:
    worker_identity = f"{socket.gethostname()}-{os.getpid()}"
    print(f"âš ï¸ è­¦å‘Š: æœªé…ç½® WORKER_IDï¼Œä½¿ç”¨éšæœºID: {worker_identity}")
CONSUMER_NAME = f"worker-{worker_identity}"

try:
    nacos_client = nacos.NacosClient(NACOS_SERVER_ADDR, namespace=NACOS_NAMESPACE)
    debug_log(f"âœ… Nacos å®¢æˆ·ç«¯å·²è¿æ¥: {NACOS_SERVER_ADDR}", "INFO")
except Exception as e:
    debug_log(f"âŒ Nacos è¿æ¥å¤±è´¥: {e}", "ERROR")
    nacos_client = None

# åˆå§‹åŒ– Redis è¿æ¥
redis_client = redis.Redis(host=REDIS_HOST, port=REDIS_PORT, db=0)

GEMINI_REFUSAL_KEYWORDS = [
    "æ‚¨ç™»å½•äº†å—",
    "æ— æ³•ä¸ºæ‚¨åˆ›å»ºä»»ä½•å›¾ç‰‡",
    "åœ°åŒºå°šæœªå¼€é€š",
    "æ— æ³•åˆ›å»ºå›¾ç‰‡",
    "I cannot create images",
    "yet available to create images"
]

def init_stream():
    """åˆå§‹åŒ– Stream å’Œ æ¶ˆè´¹è€…ç»„"""
    try:
        redis_client.xgroup_create(STREAM_KEY, GROUP_NAME, id='0', mkstream=True)
        debug_log(f"æ¶ˆè´¹è€…ç»„ {GROUP_NAME} å°±ç»ª", "INFO")
    except redis.exceptions.ResponseError as e:
        if "BUSYGROUP" in str(e):
            debug_log(f"æ¶ˆè´¹è€…ç»„ {GROUP_NAME} å·²å­˜åœ¨", "INFO")
        else:
            raise e

def process_message(message_id, message_data, check_idempotency=True):
    """
    å¤„ç†å•æ¡æ¶ˆæ¯çš„æ ¸å¿ƒé€»è¾‘ (ä¼˜åŒ–ç‰ˆï¼šè¶…æ—¶ç†”æ–­ + è½¯æ‹’ç»æ£€æµ‹)
    """
    db = database.SessionLocal()
    task_data = parse_and_validate(
        redis_client, STREAM_KEY, GROUP_NAME, message_id, message_data, CONSUMER_NAME
    )

    # å¦‚æœè¿”å› Noneï¼Œè¯´æ˜æ˜¯çƒ‚æ¶ˆæ¯ä¸”å·²ç»è¢« helper å¤„ç†æ‰äº†ï¼Œç›´æ¥æ”¶å·¥
    if not task_data:
        db.close()
        return

    task_id = task_data.get('task_id')
    conversation_id = task_data.get('conversation_id')
    prompt = task_data.get('prompt')
    model = task_data.get('model')

    try:
        # =========================================================
        # ğŸ”¥ å¹‚ç­‰æ€§æ£€æŸ¥
        # =========================================================
        if check_idempotency:
            # ç›´æ¥è°ƒç”¨å…¬å…±å‡½æ•°å°è¯•æŠ¢å 
            if not claim_task(db, task_id):
                # å¦‚æœæŠ¢å å¤±è´¥ (è¿”å›False)ï¼Œè¯´æ˜ä»»åŠ¡æ­£åœ¨è·‘æˆ–è·‘å®Œäº†
                # ç›´æ¥ ACK å‘Šè¯‰ Redis "è¿™äº‹ä¸ç”¨æˆ‘ç®¡äº†"
                redis_client.xack(STREAM_KEY, GROUP_NAME, message_id)
                return
        # =========================================================

        debug_log(f"å¼€å§‹å¤„ç†: {task_id}", "REQUEST")

        # --- 2. è°ƒç”¨ä¸‹æ¸¸ AI æœåŠ¡ ---
        payload = {
            "model": model,
            "conversation_id": conversation_id,
            "messages": [{"role": "user", "content": prompt}]
        }

        target_url = get_nacos_target_url(db, conversation_id, nacos_client, SERVICE_NAME)

        if not target_url:
            error_msg = "æ— æ³•è·å–æœ‰æ•ˆçš„ Gemini æœåŠ¡åœ°å€ (Nacos Empty)"
            mark_task_failed(db, task_id, error_msg)
            redis_client.xack(STREAM_KEY, GROUP_NAME, message_id)
            return

        debug_log(f"å‘é€è¯·æ±‚åˆ°: {target_url}", "REQUEST")

        headers = {"Content-Type": "application/json"}

        start_time = time.time()
        response = requests.post(target_url, json=payload, headers=headers, timeout=120)


        if response.status_code == 200:
            # === HTTP æˆåŠŸï¼Œä½†éœ€æ£€æŸ¥ä¸šåŠ¡å†…å®¹ ===
            res_json = response.json()
            ai_text = res_json['choices'][0]['message']['content']
            cost_time = round(time.time() - start_time, 2)

            # ğŸ”¥ æ ¸å¿ƒä¿®æ”¹ï¼šä¸€è¡Œä»£ç æå®š å®¡æŸ¥ + ä¿å­˜ + çŠ¶æ€æ›´æ–°
            process_ai_result(
                db,
                task_id,
                ai_text,
                cost_time,
                conversation_id,
                refusal_keywords=GEMINI_REFUSAL_KEYWORDS  # ä¼ å…¥ç”±äº Gemini ç‰¹æ€§çš„æ‹’ç»è¯
            )

            # æ— è®ºæˆåŠŸè¿˜æ˜¯è¢«æ‹¦æˆªï¼Œéƒ½ ACK æ‰ï¼Œé¿å…é‡å¤æ¶ˆè´¹
            redis_client.xack(STREAM_KEY, GROUP_NAME, message_id)

        else:
            # === HTTP çŠ¶æ€ç é”™è¯¯ (é 200) ===
            error_msg = f"Gemini API Error: {response.status_code} - {response.text[:100]}"
            debug_log(error_msg, "ERROR")
            mark_task_failed(db, task_id, error_msg)
            redis_client.xack(STREAM_KEY, GROUP_NAME, message_id)

    except ConnectTimeout:
        error_msg = "æ— æ³•è¿æ¥åˆ° AI æœåŠ¡ (Connection Timeout)ã€‚è¯·æ£€æŸ¥ API åœ°å€æˆ–é˜²ç«å¢™é…ç½®ã€‚"
        debug_log(f"ğŸ”Œ {error_msg}", "ERROR")

        mark_task_failed(db, task_id, "ç³»ç»Ÿå†…éƒ¨è¿æ¥å¼‚å¸¸ï¼Œè¯·è”ç³»ç®¡ç†å‘˜")
        redis_client.xack(STREAM_KEY, GROUP_NAME, message_id)

        # 2. å†æ•è·è¯»å–è¶…æ—¶ (çœŸæ­£çš„ >120ç§’)
    except Timeout:
        error_msg = "AI ç”Ÿæˆè¶…æ—¶ï¼ˆè¶…è¿‡ 2 åˆ†é’Ÿæ— å“åº”ï¼‰ï¼Œè¯·ç¨åé‡è¯•ã€‚"
        debug_log(f"â³ {error_msg}", "ERROR")

        mark_task_failed(db, task_id, error_msg)
        redis_client.xack(STREAM_KEY, GROUP_NAME, message_id)

    except RequestException as e:
        # å…¶ä»–ç½‘ç»œé”™è¯¯ (è¿æ¥è¢«æ‹’ã€DNSè§£æå¤±è´¥ç­‰)
        error_msg = f"ç½‘ç»œè¿æ¥å¼‚å¸¸: {str(e)}"
        debug_log(error_msg, "ERROR")

        mark_task_failed(db, task_id, "åç«¯æœåŠ¡è¿æ¥ä¸­æ–­")
        redis_client.xack(STREAM_KEY, GROUP_NAME, message_id)

    except Exception as e:
        db.rollback()
        # ä»£ç é€»è¾‘å´©æºƒ
        debug_log(f"Worker å†…éƒ¨å´©æºƒ: {e}", "ERROR")
        mark_task_failed(db, task_id, "ç³»ç»Ÿå†…éƒ¨å¤„ç†é”™è¯¯")
        redis_client.xack(STREAM_KEY, GROUP_NAME, message_id)

    finally:
        db.close()



def start_worker():
    debug_log("=" * 40, "INFO")
    debug_log(f"ğŸš€ Stream Worker å¯åŠ¨ (Fail Fast Mode): {CONSUMER_NAME}", "INFO")

    init_stream()

    # 1. ä»…åœ¨å¯åŠ¨æ—¶æ£€æŸ¥ä¸€æ¬¡
    recover_pending_tasks(
        redis_client=redis_client,
        stream_key=STREAM_KEY,
        group_name=GROUP_NAME,
        consumer_name=CONSUMER_NAME,
        process_callback=process_message  # <--- å‡½æ•°ä½œä¸ºå‚æ•°ä¼ é€’
    )

    debug_log("è¿›å…¥ä¸»å¾ªç¯ç›‘å¬...", "INFO")

    # 2. ä¸»å¾ªç¯ (ä¸å†æœ‰å®šæ—¶æ£€æŸ¥)
    while True:
        try:
            # é˜»å¡è¯»å–æ–°æ¶ˆæ¯
            response = redis_client.xreadgroup(
                GROUP_NAME, CONSUMER_NAME, {STREAM_KEY: '>'}, count=1, block=2000
            )

            if not response:
                continue

            stream_name, messages = response[0]
            for message_id, message_data in messages:
                process_message(message_id, message_data, check_idempotency=False)

        except Exception as e:
            debug_log(f"ä¸»å¾ªç¯å¼‚å¸¸: {e}", "ERROR")
            time.sleep(5)  # é˜²æ­¢ Redis æŒ‚äº†å¯¼è‡´æ­»å¾ªç¯åˆ·å±


if __name__ == "__main__":
    start_worker()