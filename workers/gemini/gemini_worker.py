# workers/gemini/gemini_worker.py
import json
import os
import time
import socket
from pathlib import Path
from datetime import datetime
from requests.exceptions import RequestException, Timeout, ConnectTimeout
import redis
import requests
from dotenv import load_dotenv

# å¯¼å…¥å…±äº«æ¨¡å—
from shared import models, database
from shared.models import TaskStatus
from shared.utils.task_helper import log_error, debug_log, mark_task_failed

# --- 1. ç¯å¢ƒé…ç½®ä¸åŠ è½½ ---
current_file_path = Path(__file__).resolve()
project_root = current_file_path.parent.parent.parent
env_path = project_root / ".env"

if env_path.exists():
    load_dotenv(env_path)
    print(f"âœ… å·²åŠ è½½ç¯å¢ƒå˜é‡: {env_path}")
else:
    print(f"âš ï¸ æœªæ‰¾åˆ°ç¯å¢ƒå˜é‡æ–‡ä»¶: {env_path}")

# --- 2. å…¨å±€é…ç½® ---
REDIS_HOST = os.getenv("REDIS_HOST", "127.0.0.1")
REDIS_PORT = int(os.getenv("REDIS_PORT", 6379))
GEMINI_SERVICE_URL = os.getenv("GEMINI_SERVICE_URL", "http://192.168.202.155:61028/v1/chat/completions")
DEBUG = True

# Stream é…ç½®
STREAM_KEY = "gemini_stream"
GROUP_NAME = "gemini_workers_group"

# Worker èº«ä»½æ ‡è¯†
worker_identity = os.getenv("WORKER_ID")
if not worker_identity:
    worker_identity = f"{socket.gethostname()}-{os.getpid()}"
    print(f"âš ï¸ è­¦å‘Š: æœªé…ç½® WORKER_IDï¼Œä½¿ç”¨éšæœºID: {worker_identity}")
CONSUMER_NAME = f"worker-{worker_identity}"

# åˆå§‹åŒ– Redis è¿æ¥
redis_client = redis.Redis(host=REDIS_HOST, port=REDIS_PORT, db=0)


def init_stream():
    """åˆå§‹åŒ– Stream å’Œ æ¶ˆè´¹è€…ç»„"""
    try:
        redis_client.xgroup_create(STREAM_KEY, GROUP_NAME, id='0', mkstream=True)
        debug_log(f"æ¶ˆè´¹è€…ç»„ {GROUP_NAME} å°±ç»ª", "INFO")
    except redis.exceptions.ResponseError as e:
        if "BUSYGROUP" in str(e):
            debug_log(f"æ¶ˆè´¹è€…ç»„ {GROUP_NAME} å·²å­˜åœ¨", "INFO")
        else:
            raise e

def process_message(message_id, message_data, check_idempotency=True):
    """
    å¤„ç†å•æ¡æ¶ˆæ¯çš„æ ¸å¿ƒé€»è¾‘ (ä¼˜åŒ–ç‰ˆï¼šè¶…æ—¶ç†”æ–­ + è½¯æ‹’ç»æ£€æµ‹)
    """
    db = database.SessionLocal()
    task_id = "UNKNOWN"
    existing_task = None

    try:
        # --- 1. è§£æ Redis æ¶ˆæ¯ ---
        payload_bytes = message_data.get(b'payload')
        if not payload_bytes:
            debug_log(f"æ¶ˆæ¯æ ¼å¼é”™è¯¯ (ç¼º payload): {message_data}", "ERROR")
            redis_client.xack(STREAM_KEY, GROUP_NAME, message_id)
            return

        task_data = json.loads(payload_bytes)
        task_id = task_data.get('task_id')
        conversation_id = task_data.get('conversation_id')
        prompt = task_data.get('prompt')
        model = task_data.get('model')

        # =========================================================
        # ğŸ”¥ å¹‚ç­‰æ€§æ£€æŸ¥
        # =========================================================
        if check_idempotency:
            existing_task = db.query(models.Task).filter(models.Task.task_id == task_id).first()
            if existing_task and existing_task.status != TaskStatus.PENDING:
                debug_log(f"â™»ï¸ [å¹‚ç­‰æ‹¦æˆª] ä»»åŠ¡ {task_id} å·²å¤„ç†ï¼ŒçŠ¶æ€: {existing_task.status}", "WARNING")
                redis_client.xack(STREAM_KEY, GROUP_NAME, message_id)
                return
        # =========================================================

        debug_log(f"å¼€å§‹å¤„ç†: {task_id}", "REQUEST")

        # --- 2. è°ƒç”¨ä¸‹æ¸¸ AI æœåŠ¡ ---
        payload = {
            "model": model,
            "conversation_id": conversation_id,
            "messages": [{"role": "user", "content": prompt}]
        }

        start_time = time.time()

        # =========================================================
        # âš¡ ä¼˜åŒ–ç‚¹ 1ï¼šè¶…æ—¶è®¾ç½® (timeout=120)
        # =========================================================
        # 1. æ„é€  Headers
        # å¦‚æœæ²¡æœ‰ ID (æ–°å¯¹è¯)ï¼Œå°±å¡«ä¸ªé»˜è®¤å€¼ï¼ŒNginx ä¼šæŠŠå®ƒåˆ†é…ç»™ä»»æ„èŠ‚ç‚¹
        headers = {
            "Content-Type": "application/json",
            "X-Conversation-ID": str(conversation_id) if conversation_id else "new-session"
        }

        # 2. å‘é€è¯·æ±‚æ—¶å¸¦ä¸Š headers
        debug_log(f"å‘é€è¯·æ±‚åˆ° Nginx, Conversation-ID: {headers['X-Conversation-ID']}", "INFO")
        response = requests.post(GEMINI_SERVICE_URL, json=payload, headers=headers, timeout=120)

        if response.status_code == 200:
            # === HTTP æˆåŠŸï¼Œä½†éœ€æ£€æŸ¥ä¸šåŠ¡å†…å®¹ ===
            res_json = response.json()
            ai_text = res_json['choices'][0]['message']['content']

            # =========================================================
            # âš¡ ä¼˜åŒ–ç‚¹ 2ï¼šè½¯æ‹’ç»æ£€æµ‹ (Soft Rejection)
            # æ£€æµ‹ Google æ˜¯å¦è¿”å›äº†â€œæœªç™»å½•/æ— æ³•ç”Ÿæˆå›¾ç‰‡â€çš„æ‹’ç»è¯æœ¯
            # =========================================================
            refusal_keywords = [
                "æ‚¨ç™»å½•äº†å—",
                "æ— æ³•ä¸ºæ‚¨åˆ›å»ºä»»ä½•å›¾ç‰‡",
                "åœ°åŒºå°šæœªå¼€é€š",
                "æ— æ³•åˆ›å»ºå›¾ç‰‡",
                "I cannot create images",
                "yet available to create images"
            ]

            # æ£€æŸ¥å›å¤ä¸­æ˜¯å¦åŒ…å«ä¸Šè¿°ä»»æ„å…³é”®è¯
            is_refusal = any(keyword in ai_text for keyword in refusal_keywords)

            if is_refusal:
                # å‘½ä¸­æ‹’ç»å…³é”®è¯ -> è§†ä¸ºå¤±è´¥
                error_msg = f"AI æœåŠ¡å‡ºé”™äº†: {ai_text}"
                debug_log(f"ğŸ›‘ æ•è·åˆ°è½¯æ‹’ç»: {error_msg}", "ERROR")

                # è®°å½•è¯¦ç»†æ—¥å¿—ä¾›ç®¡ç†å‘˜æ’æŸ¥
                log_error("Worker-Gemini", error_msg, task_id)

                # æ ‡è®°æ•°æ®åº“ä¸º FAILEDï¼Œå¹¶å°† AI çš„æ‹’ç»ç†ç”±å±•ç¤ºç»™ç”¨æˆ·
                mark_task_failed(db, task_id, f"å›¾ç‰‡ç”Ÿæˆå¤±è´¥: {ai_text}")

            else:
                # çœŸæ­£çš„æˆåŠŸ
                if not existing_task:
                    existing_task = db.query(models.Task).filter(models.Task.task_id == task_id).first()

                if existing_task:
                    existing_task.response_text = ai_text
                    existing_task.status = TaskStatus.SUCCESS
                    existing_task.cost_time = round(time.time() - start_time, 2)

                    conv = db.query(models.Conversation).filter(
                        models.Conversation.conversation_id == conversation_id).first()
                    if conv:
                        conv.updated_at = datetime.now()

                    db.commit()
                    debug_log(f"ä»»åŠ¡å®Œæˆ: {task_id} (è€—æ—¶: {existing_task.cost_time:.2f}s)", "SUCCESS")

            # æ— è®ºæˆåŠŸè¿˜æ˜¯è¢«æ‹¦æˆªï¼Œéƒ½ ACK æ‰ï¼Œé¿å…é‡å¤æ¶ˆè´¹
            redis_client.xack(STREAM_KEY, GROUP_NAME, message_id)

        else:
            # === HTTP çŠ¶æ€ç é”™è¯¯ (é 200) ===
            error_msg = f"Gemini API Error: {response.status_code} - {response.text[:100]}"
            debug_log(error_msg, "ERROR")
            log_error("Worker-Gemini", error_msg, task_id)
            mark_task_failed(db, task_id, error_msg)
            redis_client.xack(STREAM_KEY, GROUP_NAME, message_id)

    except (json.JSONDecodeError, UnicodeDecodeError) as e:
        debug_log(f"æ•°æ®è§£æå¤±è´¥: {e}", "ERROR")
        redis_client.xack(STREAM_KEY, GROUP_NAME, message_id)

    # =========================================================
    # âš¡ ä¼˜åŒ–ç‚¹ 3ï¼šæ˜ç¡®æ•è·è¶…æ—¶å¼‚å¸¸
    # =========================================================
    except ConnectTimeout:
        error_msg = "æ— æ³•è¿æ¥åˆ° AI æœåŠ¡ (Connection Timeout)ã€‚è¯·æ£€æŸ¥ API åœ°å€æˆ–é˜²ç«å¢™é…ç½®ã€‚"
        debug_log(f"ğŸ”Œ {error_msg}", "ERROR")
        log_error("Worker-Gemini", "Connect Timeout", task_id)

        mark_task_failed(db, task_id, "ç³»ç»Ÿå†…éƒ¨è¿æ¥å¼‚å¸¸ï¼Œè¯·è”ç³»ç®¡ç†å‘˜")
        redis_client.xack(STREAM_KEY, GROUP_NAME, message_id)

        # 2. å†æ•è·è¯»å–è¶…æ—¶ (çœŸæ­£çš„ >120ç§’)
    except Timeout:
        error_msg = "AI ç”Ÿæˆè¶…æ—¶ï¼ˆè¶…è¿‡ 2 åˆ†é’Ÿæ— å“åº”ï¼‰ï¼Œè¯·ç¨åé‡è¯•ã€‚"
        debug_log(f"â³ {error_msg}", "ERROR")
        log_error("Worker-Gemini", "Read Timeout (>120s)", task_id)

        mark_task_failed(db, task_id, error_msg)
        redis_client.xack(STREAM_KEY, GROUP_NAME, message_id)

    except RequestException as e:
        # å…¶ä»–ç½‘ç»œé”™è¯¯ (è¿æ¥è¢«æ‹’ã€DNSè§£æå¤±è´¥ç­‰)
        error_msg = f"ç½‘ç»œè¿æ¥å¼‚å¸¸: {str(e)}"
        debug_log(error_msg, "ERROR")
        log_error("Worker-Gemini", "Network Error", task_id, e)

        mark_task_failed(db, task_id, "åç«¯æœåŠ¡è¿æ¥ä¸­æ–­")
        redis_client.xack(STREAM_KEY, GROUP_NAME, message_id)

    except Exception as e:
        # ä»£ç é€»è¾‘å´©æºƒ
        debug_log(f"Worker å†…éƒ¨å´©æºƒ: {e}", "ERROR")
        log_error("Worker-Gemini", "Unknown Exception", task_id, e)
        mark_task_failed(db, task_id, "ç³»ç»Ÿå†…éƒ¨å¤„ç†é”™è¯¯")
        redis_client.xack(STREAM_KEY, GROUP_NAME, message_id)

    finally:
        db.close()


def recover_pending_tasks():
    """
    å¯åŠ¨æ—¶æ¢å¤é€»è¾‘
    åªå¤„ç†é‚£äº› "Worker çªç„¶æ–­ç”µå¯¼è‡´æ²¡æ¥å¾—åŠ ACK" çš„ä»»åŠ¡
    """
    try:
        # è·å–æ‰€æœ‰å·²è®¤é¢†ä½†æœª ACK çš„æ¶ˆæ¯
        response = redis_client.xreadgroup(
            GROUP_NAME, CONSUMER_NAME, {STREAM_KEY: '0'}, count=50, block=None
        )

        if response:
            stream_name, messages = response[0]
            if messages:
                debug_log(f"â™»ï¸  Worker é‡å¯ï¼Œæ­£åœ¨æ¢å¤ {len(messages)} ä¸ªæŒ‚èµ·ä»»åŠ¡...", "WARNING")

                for message_id, message_data in messages:
                    # é‡æ–°å¤„ç† (check_idempotency=True ä¼šæ‹¦æˆªå·²å¤±è´¥/å·²æˆåŠŸçš„ä»»åŠ¡)
                    # è¿™é‡Œçš„é€»è¾‘æ˜¯ï¼šä¸ç®¡ä¹‹å‰å¤±è´¥äº†å‡ æ¬¡ï¼Œåªè¦è¿˜åœ¨ Pending é‡Œï¼Œå°±å†è¯•ä¸€æ¬¡ã€‚
                    # å¦‚æœè¿™æ¬¡å¤„ç†å› ä¸º Exception å´©æºƒäº†å¹¶è¢«æ•è·ï¼Œprocess_message é‡Œä¼šæ‰§è¡Œ ACKï¼Œå¾ªç¯ç»“æŸã€‚
                    process_message(message_id, message_data, check_idempotency=True)

                debug_log("âœ… æŒ‚èµ·ä»»åŠ¡å¤„ç†å®Œæ¯•", "INFO")
    except Exception as e:
        debug_log(f"æ¢å¤ Pending ä»»åŠ¡å¤±è´¥: {e}", "ERROR")


def start_worker():
    debug_log("=" * 40, "INFO")
    debug_log(f"ğŸš€ Stream Worker å¯åŠ¨ (Fail Fast Mode): {CONSUMER_NAME}", "INFO")

    init_stream()

    # 1. ä»…åœ¨å¯åŠ¨æ—¶æ£€æŸ¥ä¸€æ¬¡
    recover_pending_tasks()

    debug_log("è¿›å…¥ä¸»å¾ªç¯ç›‘å¬...", "INFO")

    # 2. ä¸»å¾ªç¯ (ä¸å†æœ‰å®šæ—¶æ£€æŸ¥)
    while True:
        try:
            # é˜»å¡è¯»å–æ–°æ¶ˆæ¯
            response = redis_client.xreadgroup(
                GROUP_NAME, CONSUMER_NAME, {STREAM_KEY: '>'}, count=1, block=2000
            )

            if not response:
                continue

            stream_name, messages = response[0]
            for message_id, message_data in messages:
                process_message(message_id, message_data, check_idempotency=False)

        except Exception as e:
            debug_log(f"ä¸»å¾ªç¯å¼‚å¸¸: {e}", "ERROR")
            time.sleep(5)  # é˜²æ­¢ Redis æŒ‚äº†å¯¼è‡´æ­»å¾ªç¯åˆ·å±


if __name__ == "__main__":
    start_worker()